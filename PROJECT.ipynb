{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    " \n",
    "consumer_key = 'consumer_Key'\n",
    "consumer_secret = 'consumer_secret'\n",
    "access_token = 'access_token'\n",
    "access_secret = 'access_secret'\n",
    " \n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for tweet in tweepy.Cursor(api.search, q='%23test432').items(500):\n",
    "    results.append(tweet)\n",
    "\n",
    "print type(results)\n",
    "print len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def toDataFrame(tweets):\n",
    "\n",
    "    DataSet = pd.DataFrame()\n",
    "\n",
    "    DataSet['tweetID'] = [tweet.id for tweet in tweets]\n",
    "    DataSet['tweetText'] = [tweet.text for tweet in tweets]\n",
    "    DataSet['tweetRetweetCt'] = [tweet.retweet_count for tweet \n",
    "    in tweets]\n",
    "    DataSet['tweetFavoriteCt'] = [tweet.favorite_count for tweet \n",
    "    in tweets]\n",
    "    DataSet['tweetSource'] = [tweet.source for tweet in tweets]\n",
    "    DataSet['tweetCreated'] = [tweet.created_at for tweet in tweets]\n",
    "\n",
    "\n",
    "    DataSet['userID'] = [tweet.user.id for tweet in tweets]\n",
    "    DataSet['userScreen'] = [tweet.user.screen_name for tweet \n",
    "    in tweets]\n",
    "    DataSet['userName'] = [tweet.user.name for tweet in tweets]\n",
    "    DataSet['userCreateDt'] = [tweet.user.created_at for tweet \n",
    "    in tweets]\n",
    "    DataSet['userDesc'] = [tweet.user.description for tweet in tweets]\n",
    "    DataSet['userFollowerCt'] = [tweet.user.followers_count for tweet \n",
    "    in tweets]\n",
    "    DataSet['userFriendsCt'] = [tweet.user.friends_count for tweet \n",
    "    in tweets]\n",
    "    DataSet['userLocation'] = [tweet.user.location for tweet in tweets]\n",
    "    DataSet['userTimezone'] = [tweet.user.time_zone for tweet \n",
    "    in tweets]\n",
    "\n",
    "    return DataSet\n",
    "\n",
    "#Pass the tweets list to the above function to create a DataFrame\n",
    "tweet_frame = toDataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetID</th>\n",
       "      <th>tweetText</th>\n",
       "      <th>tweetRetweetCt</th>\n",
       "      <th>tweetFavoriteCt</th>\n",
       "      <th>tweetSource</th>\n",
       "      <th>tweetCreated</th>\n",
       "      <th>userID</th>\n",
       "      <th>userScreen</th>\n",
       "      <th>userName</th>\n",
       "      <th>userCreateDt</th>\n",
       "      <th>userDesc</th>\n",
       "      <th>userFollowerCt</th>\n",
       "      <th>userFriendsCt</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userTimezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>751954883784241152</td>\n",
       "      <td>Great job ðŸ‘Ž  #test432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>2016-07-10 01:43:09</td>\n",
       "      <td>4721235721</td>\n",
       "      <td>WaldoJoe_</td>\n",
       "      <td>Waldo Joe</td>\n",
       "      <td>2016-01-07 01:48:07</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetID               tweetText  tweetRetweetCt  \\\n",
       "0  751954883784241152  Great job ðŸ‘Ž  #test432               0   \n",
       "\n",
       "   tweetFavoriteCt         tweetSource        tweetCreated      userID  \\\n",
       "0                0  Twitter for iPhone 2016-07-10 01:43:09  4721235721   \n",
       "\n",
       "  userScreen   userName        userCreateDt userDesc  userFollowerCt  \\\n",
       "0  WaldoJoe_  Waldo Joe 2016-01-07 01:48:07                        7   \n",
       "\n",
       "   userFriendsCt userLocation userTimezone  \n",
       "0             33                      None  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_frame[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apple = tweet_frame[0:1].to_csv(\"zebra1.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "153\n",
      "268\n"
     ]
    }
   ],
   "source": [
    "nltk_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "print type(nltk_stopwords)\n",
    "print len(nltk_stopwords)\n",
    "my_stopwords = nltk_stopwords + [\"br\", \"\\r\", \"\\n\", '\\r\\n\\r\\n', \"said\", \"000\", \"amto\", \"jdemarco\", \"demarco\", \"joe\",\"mailto\", \"ambassador\",\"ambassador hc\",\"mo\", \"com\",\"Thank\", 'revenue management', 'revenue management', 'cc', 'email',\n",
    "                                 \"Ambassador\",\"2015\",'thank chrm','thank','chrm','director revenue','pm',\"pmto\", \"cssgbcorporate\", \n",
    "                                 'director', 'http', 'subject', 'hotel collection', 'hotel','collection', 'managementambassador',\n",
    "                                 'ambassadorhc','sent','thank chrm', 'corporate', 'ambassadorhotelcollection', 'cssgb',\n",
    "                                u'00', u'01', u'02', u'03', u'04', u'06', u'08', u'10', u'104', u'104 broadway', u'107', u'107 9th', u'11', u'1111', u'1111 grand', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', '' u'20', u'2016', u'21', u'22', u'23', u'24', u'25', u'26', '________________________________From:', u'27', u'28', u'29', u'30', u'31', u'316', u'316 719', u'326', u'400', u'400 tulsa', u'405', u'64105', u'64105 jdemarco', u'64106', u'64106 816', u'67202', u'67202 316', u'67202 ambassadorhotelcollection', u'704', u'704 770', u'7134', u'7134 suite', u'719', u'719 7192', u'7192', u'7192 wichita', u'74136', u'74136 704', u'770', u'770 8118', u'8118', u'8118 107', u'8118 jdemarco', u'816', u'816 326', u'918', u'9th', u'9th kansas', u'________________________________', u'__________________________________________________', u'__________________________________________________ join', ]\n",
    "print len(my_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 17)\n",
      "['Unnamed: 0', 'tweetID', 'tweetText', 'tweetRetweetCt', 'tweetFavoriteCt', 'tweetSource', 'tweetCreated', 'userID', 'userScreen', 'userName', 'userCreateDt', 'userDesc', 'userFollowerCt', 'userFriendsCt', 'userLocation', 'userTimezone', 'newtext']\n",
      "(1, 3)\n",
      "<type 'list'> 3\n",
      "<type 'list'> 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:30: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "from __future__ import division\n",
    "pathname = \"C:\\Users\\joed.AMBHO\\Desktop\\pycourse\\project\\zebra1.csv\"\n",
    "pd.set_option('display.max_colwidth', 1500)\n",
    "sentdf = pathname\n",
    "sentdf = pd.read_csv(sentdf)\n",
    "sentdf['newtext'] = map(lambda x: x.decode('latin-1').encode('ascii','ignore'), sentdf['tweetText'])\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "print sentdf.shape\n",
    "print list(sentdf)\n",
    "sentdf['newtext'] = map(lambda x: x.replace('\\r\\n', ''), sentdf['tweetText'])\n",
    "sentdf['newtext'] = map(lambda x: x.replace('________________________________, ', ''), sentdf['tweetText'])\n",
    "prelim = CountVectorizer(binary=False, lowercase = False, stop_words = 'english') \n",
    "prelim_dm = prelim.fit_transform(sentdf['newtext'])\n",
    "print prelim_dm.shape\n",
    "sentdf['newstext'] = sentdf['newtext'].replace('\\r\\n', '')\n",
    "names = prelim.get_feature_names()\n",
    "print type(names), len(names)\n",
    "\n",
    "count = np.sum(prelim_dm.toarray(), axis = 0).tolist()\n",
    "print type(count), len(count)\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort(['count'], ascending = False).head(20)\n",
    "import re\n",
    "news_dict = { ' rate ':' ADR ', ' property ':' hotel ', ' RevPARs ' : ' RevPAR ', ' Brunch' : ' Breakfast ', ' Oklahoma City ' : ' OKC ', ' Kansas City ': ' KC ', ' tulak ': ' Tulsa ', ' ICTAK ': ' Wichita ', ' mciaa ': ' KC ', ' okcak ': ' OKC '}\n",
    "\n",
    "\n",
    "def multiple_replace(dict, text): \n",
    "\n",
    "  \"\"\" Replace in 'text' all occurences of any key in the given\n",
    "  dictionary by its corresponding value.  Returns the new tring.\"\"\" \n",
    "  text = str(text).lower()\n",
    "\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)\n",
    "\n",
    "sentdf['newtext'] = map(lambda x: multiple_replace(news_dict, x), sentdf['newtext'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: I will be looking at all of my sent and recieved emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    1\n",
       "Name: afinn, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn = dict(map(lambda (k,v): (k,int(v)), [ line.split('\\t') for line in open(\"C:\\Users\\joed.AMBHO\\Desktop\\pycourse\\week5\\AFINN-111.txt\") ]))\n",
    "\n",
    "def afinn_sent(inputstring):\n",
    "    \n",
    "    sentcount =0\n",
    "    for word in inputstring.split():  \n",
    "        if word in afinn:\n",
    "            sentcount = sentcount + afinn[word]\n",
    "            \n",
    "    \n",
    "    if (sentcount < 0):\n",
    "        sentiment = 'Negative'\n",
    "    elif (sentcount >0):\n",
    "        sentiment = 'Positive'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    \n",
    "    return sentiment\n",
    "    #return sentcount\n",
    "\n",
    "sentdf['afinn'] = map(lambda x: afinn_sent(x), sentdf['newtext'])\n",
    "sentdf['afinn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 3)\n",
      "<type 'list'> 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv1 = CountVectorizer(lowercase=True, \n",
    "                     stop_words='english',\n",
    "                     binary=False,\n",
    "                     ngram_range = (1,2)) \n",
    "tfidf1 = TfidfVectorizer(lowercase=True, \n",
    "                        stop_words='english', \n",
    "                        ngram_range = (1,2)) \n",
    "\n",
    "choice = TfidfVectorizer(stop_words = 'english') \n",
    "\n",
    "cv_dm = cv1.fit_transform(sentdf['newtext'])\n",
    "tfidf_dm = tfidf1.fit_transform(sentdf['newtext'])\n",
    "choice_dm = choice.fit_transform(sentdf['newtext'])\n",
    "\n",
    "print cv_dm.shape\n",
    "print tfidf_dm.shape\n",
    "print choice_dm.shape\n",
    "names = cv1.get_feature_names()\n",
    "print type(names), len(names)\n",
    "\n",
    "count = np.sum(cv_dm.toarray(), axis = 0).tolist()\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    1\n",
       "Name: afinn, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn = dict(map(lambda (k,v): (k,int(v)), [ line.split('\\t') for line in open(\"C:\\Users\\joed.AMBHO\\Desktop\\pycourse\\week5\\AFINN-111.txt\") ]))\n",
    "\n",
    "def afinn_sent(inputstring):\n",
    "    \n",
    "    sentcount =0\n",
    "    for word in inputstring.split():  \n",
    "        if word in afinn:\n",
    "            sentcount = sentcount + afinn[word]\n",
    "            \n",
    "    \n",
    "    if (sentcount < 0):\n",
    "        sentiment = 'Negative'\n",
    "    elif (sentcount >0):\n",
    "        sentiment = 'Positive'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    \n",
    "    return sentiment\n",
    "    #return sentcount\n",
    "\n",
    "sentdf['afinn'] = map(lambda x: afinn_sent(x), sentdf['newtext'])\n",
    "sentdf['afinn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
